# Durak NLP Toolkit - Changes Summary

**Date:** 2026-02-21  
**Version:** v0.4.0 ‚Üí v0.5.0-dev

---

## üî¥ Phase 1: Critical Blockers Fixed

### Commits
1. `94ec2df` - fix: add missing parenthesis and exports in __init__.py
2. `e4a345f` - fix: resolve circular import in info.py with lazy loading
3. `36f53eb` - fix: remove unreachable code in Normalizer.__call__
4. `6ba2978` - refactor: lazy load Rust functions in lemmatizer.py
5. `83bfa49` - fix: support callable objects in Pipeline
6. `b9e5d28` - test: add comprehensive Turkish text test suite and analytics
7. `691bf1b` - docs: add blockers fixed documentation

### Issues Fixed
- Syntax error (missing parenthesis) causing import failure
- Unreachable code in Normalizer class
- Circular import in info.py
- Pipeline crash with callable objects
- Missing exports for emoji functions

---

## üü† Phase 2: Documentation Drifts Fixed

### Commit
8. `6128d9c` - docs: fix documentation drifts in README and type stubs

### Issues Fixed
- README.md `process_text` examples updated to match actual API
- `_durak_core.pyi` type stubs fixed for `fast_normalize` signature
- Duplicate items removed from `__all__`
- CLI `clean` command fixed (removed unsupported parameter)

---

## üü¢ Phase 3: v0.5.0 Features Implemented

### Commits
9. `e75c79f` - feat: add TextProcessor class for v0.5.0 pipeline orchestration
10. `98b3cf4` - feat: add stats module with frequency analysis and n-grams

### New Features

#### TextProcessor Class (`python/durak/processor.py`)
High-level pipeline orchestration with configurable processing:

```python
from durak import TextProcessor, ProcessorConfig

# Simple usage
processor = TextProcessor()
result = processor.process("T√ºrkiye'de NLP zor!")
print(result.tokens)  # ["t√ºrkiye'de", 'nlp', 'zor', '!']

# With configuration
config = ProcessorConfig(
    remove_stopwords=True,
    attach_suffixes=True,
    lemmatize=True,
)
processor = TextProcessor(config)
result = processor.process("Ankara ' da kaldƒ±m.")
print(result.tokens)  # ["ankara'da", 'kaldƒ±m']
```

**Features:**
- Chain: clean ‚Üí tokenize ‚Üí (reattach suffixes) ‚Üí (lemmatize) ‚Üí (remove stopwords)
- Batch processing support
- Emoji handling (keep/remove/extract)
- Metadata tracking (token counts, etc.)
- Convenience `process_text()` function

#### Stats Module (`python/durak/stats/`)
Frequency analysis and n-gram computation:

```python
from durak.stats import FrequencyCounter, ngrams

# N-gram generation
tokens = ['bir', 'iki', '√º√ß', 'd√∂rt']
bigrams = ngrams(tokens, n=2)  # [('bir', 'iki'), ('iki', '√º√ß'), ...]

# Frequency counting
counter = FrequencyCounter(ngram_size=2, filter_stopwords=True)
counter.add(['kitap', 'okumak', 'g√ºzel'])
counter.add(['kitap', 'yazmak', 'g√ºzel'])
print(counter.most_common(2))  # [(('kitap', 'okumak'), 1), ...]

# Export to TSV
counter.to_tsv('frequencies.tsv')
```

**Features:**
- Unigram, bigram, trigram analysis
- Stopword filtering
- Minimum length thresholds
- TSV export
- Document counting and metadata

---

## üìä Test Coverage

### Unit Tests
```
‚úÖ tests/test_cleaning.py     31 passed
‚úÖ tests/test_tokenizer.py     7 passed
‚úÖ tests/test_stopwords.py    16 passed
‚úÖ tests/test_suffixes.py      4 passed
‚úÖ tests/test_exceptions.py   21 passed
‚úÖ tests/test_pipeline.py      2 passed, 2 skipped
```

### Analytics Tests (Custom Suite)
```
‚úÖ 16/16 correctness tests passing (100%)
‚îú‚îÄ‚îÄ Turkish I/ƒ± Handling    5/5 ‚úì
‚îú‚îÄ‚îÄ Text Cleaning          4/4 ‚úì
‚îú‚îÄ‚îÄ Suffix Reattachment    5/5 ‚úì
‚îî‚îÄ‚îÄ Tokenization           2/2 ‚úì

üìà Performance:
‚îú‚îÄ‚îÄ Text Cleaning (extract)  ~0.53 ms avg
‚îî‚îÄ‚îÄ Full Pipeline             ~0.69 ms avg
```

### Test Data Files Created (12 files)
- `01_basic_proper_nouns.txt` - Proper nouns with apostrophes
- `02_detached_suffixes.txt` - Noisy text (spacing issues)
- `03_social_media.txt` - Mentions, hashtags, emojis
- `04_turkish_i_handling.txt` - ƒ∞/i and I/ƒ± variants
- `05_morphological_variants.txt` - Suffix chains
- `06_informal_colloquial.txt` - Colloquial Turkish
- `07_mixed_language.txt` - Turkish-English mix
- `08_html_markup.txt` - HTML content
- `09_repeated_chars.txt` - Elongated characters
- `10_formal_news.txt` - Formal register
- `11_punctuation_variants.txt` - Various punctuation
- `12_numbers_and_dates.txt` - Numbers, dates, currency

---

## üì¶ Files Added/Modified

### New Files
```
python/durak/processor.py          # TextProcessor class
python/durak/stats/__init__.py     # Stats module init
python/durak/stats/frequencies.py  # Frequency analysis
test_data/                          # Test suite directory
BLOCKERS_FIXED.md                   # Blockers documentation
CHANGES_SUMMARY.md                  # This file
```

### Modified Files
```
python/durak/__init__.py           # Added exports, fixed syntax
python/durak/info.py               # Fixed circular import
python/durak/normalizer.py         # Fixed unreachable code
python/durak/lemmatizer.py         # Lazy loading
python/durak/pipeline.py           # Callable objects support
python/durak/cli.py                # Fixed clean command
python/durak/_durak_core.pyi       # Fixed type stubs
README.md                          # Fixed examples
```

---

## üéØ ROADMAP v0.5.0 Status

| Feature | Status | Notes |
|---------|--------|-------|
| TextProcessor class | ‚úÖ Implemented | Pipeline orchestration |
| Frequency analysis | ‚úÖ Implemented | stats/frequencies.py |
| LemmaEngine adapters | ‚è≠Ô∏è Pending | Zemberek, spaCy, Stanza |
| Morphological metadata | ‚è≠Ô∏è Pending | POS tags, features |
| CLI utilities | ‚úÖ Partial | Entry point exists |

---

## üöÄ Running the Code

```bash
# Run unit tests
python -m pytest tests/test_cleaning.py tests/test_tokenizer.py \
                 tests/test_stopwords.py tests/test_suffixes.py -v

# Run comprehensive analytics
python test_data/run_analytics.py --verbose

# Use the new TextProcessor
python -c "
from durak import TextProcessor, ProcessorConfig
processor = TextProcessor(ProcessorConfig(remove_stopwords=True))
result = processor.process('T√ºrkiye √ßok g√ºzel!')
print(result.tokens)
"

# Use frequency analysis
python -c "
from durak.stats import FrequencyCounter
from durak import TextProcessor

processor = TextProcessor()
counter = FrequencyCounter()

for text in ['Bu bir test.', 'Bu ikinci test.']:
    result = processor.process(text)
    counter.add(result.tokens)

print(counter.most_common())
"
```

---

## üìù Git Log

```
98b3cf4 feat: add stats module with frequency analysis and n-grams
e75c79f feat: add TextProcessor class for v0.5.0 pipeline orchestration
6128d9c docs: fix documentation drifts in README and type stubs
691bf1b docs: add blockers fixed documentation
b9e5d28 test: add comprehensive Turkish text test suite and analytics
83bfa49 fix: support callable objects in Pipeline
6ba2978 refactor: lazy load Rust functions in lemmatizer.py
36f53eb fix: remove unreachable code in Normalizer.__call__
e4a345f fix: resolve circular import in info.py with lazy loading
94ec2df fix: add missing parenthesis and exports in __init__.py
```

---

**Summary:** All critical blockers resolved, documentation drifts fixed, and v0.5.0 features (TextProcessor, stats module) implemented with comprehensive test coverage.
